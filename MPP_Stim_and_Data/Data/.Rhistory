mutate(contrastName = lang.contrasts[Contrast])%>%
mutate(Group = 'LHLang-toLang')
allSigChange = rbind(allSigChange, myResults)
##TO ADD: MD to Lang localizer measure (Non should > Sent)
# myResults = read.csv('MDfROIsrespLang.csv')%>%
#   mutate(ROIName = MDROI.Names[ROI]) %>%
#   mutate(contrastName = lang.contrasts[Contrast])%>%
#   mutate(Group = 'MDall-toLang')
# allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
#allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft-toLang'
#allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight-toLang'
myResults = read.csv('NewToMfROIsrespToMLoc.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = tom.contrasts[Contrast])%>%
mutate(Group = 'ToM-toToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES
myResults = read.csv('RHLangfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'RHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('LangfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'LHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('MDfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'MDAll')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft'
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight'
myResults = read.csv('NewToMfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'ToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES-CUSTOM
myResults = read.csv('NewToMfROIsresCustomJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = custom.contrasts[Contrast])%>%
mutate(Group = 'ToMCustom')
allSigChange = rbind(allSigChange, myResults)
#View(allSigChange)
View(allSigChange)
#This rebuilds the t tests that spmss spits out from the individual signal change values (reproduced here
#so mk can track how those are done/feed into other analyses)
rm(list=ls(all=TRUE))
library(tidyr)
library(dplyr)
#Set wd!
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/contrasts")
#######
# Read in all contrast values
#######
# Add in the contrast and ROI names so it's not just numbers!!!!!
RHLangROI.Names = c('RPostTemp', 'RAntTemp', 'RAngG', 'RIFG',      'RMFG',     'RIFGorb');
LangROI.Names = c('LPostTemp', 'LAntTemp', 'LAngG', 'LIFG',      'LMFG',     'LIFGorb');
MDROI.Names = c('LIFGop',  'RIFGop', 'LMFG',    'RMFG',    'LMFGorb',
'RMFGorb', 'LPrecG', 'RPrecG',  'LInsula', 'RInsula',
'LSMA',    'RSMA',   'LParInf', 'RParInf', 'LParSup',
'RParSup', 'LACC',   'RACC');
ToMROI.Names = c('DMPFC', 'LTPJ',  'MMPFC', 'PC',
'RTPJ',  'VMPFC', 'RSTS');
lang.contrasts = c('sent','non','sent-non')
md.contrasts = c()
tom.contrasts = c('bel','pho','bel-pho')
normal.contrasts = c('joke', 'lit', 'joke-lit')
custom.contrasts = c('low','med','high','other')
###RESP LOCALIZER
myResults = read.csv('RHLangfROIsrespLangLoc.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = lang.contrasts[Contrast])%>%
mutate(Group = 'RHLang-toLang')
allSigChange = myResults
myResults = read.csv('LangfROIsrespLangLoc.csv')%>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = lang.contrasts[Contrast])%>%
mutate(Group = 'LHLang-toLang')
allSigChange = rbind(allSigChange, myResults)
##TO ADD: MD to Lang localizer measure (Non should > Sent)
# myResults = read.csv('MDfROIsrespLang.csv')%>%
#   mutate(ROIName = MDROI.Names[ROI]) %>%
#   mutate(contrastName = lang.contrasts[Contrast])%>%
#   mutate(Group = 'MDall-toLang')
# allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
#allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft-toLang'
#allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight-toLang'
myResults = read.csv('NewToMfROIsrespToMLoc.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = tom.contrasts[Contrast])%>%
mutate(Group = 'ToM-toToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES
myResults = read.csv('RHLangfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'RHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('LangfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'LHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('MDfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'MDAll')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft'
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight'
myResults = read.csv('NewToMfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'ToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES-CUSTOM
myResults = read.csv('NewToMfROIsresCustomJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = custom.contrasts[Contrast])%>%
mutate(Group = 'ToMCustom')
allSigChange = rbind(allSigChange, myResults)
#View(allSigChange)
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, ROI, Contrast, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, Contrast)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
#View(allTests)
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/reproducible analyses")
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
########
# Report those T tests like we want for the paper
########
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
allTests %>%
filter(Group == 'LHLang-toLang', contrastName == 'sent-non') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
allTests %>%
filter(Group == 'LHLang-toLang', contrastName == 'sent-non') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
#allTests %>%
#  filter(Group == 'RHLang-toLang', contrastName == 'sent-non') %>%
#  summarise(n(), sum(sig), reportTests(t,p)) #found a surprise nonsig!
allTests %>%
filter(Group == 'RHLang-toLang', contrastName == 'sent-non', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang-toLang', contrastName == 'sent-non', !sig)
library(lme4)
help(glmer)
help(lmer)
names(allSigChange)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", contrastName == "sent" || contrastName == "non")
View(LHLangtoLang)
LHLangtoLang <- filter(allSigChange, contrastName == "sent" || contrastName == "non")
View(LHLangtoLang)
LHLangtoLang <- filter(allSigChange, contrast < 3)
LHLangtoLang <- filter(allSigChange, Contrast < 3)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", Contrast < 3)
View(LHLangtoLang)
names(allSigChange)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", Contrast < 3)
m1 <- glmer(sigChange ~ contrastName + (1|ROI) + (1|SubjectNumber), data = LHLangtoLang, family = "gaussian")
m1 <- lmer(sigChange ~ contrastName + (1|ROI) + (1|SubjectNumber), data = LHLangtoLang)
summary(m1)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", Contrast < 3)
m1 <- lmer(sigChange ~ contrastName + (1|ROI) + (1|SubjectNumber), data = LHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (1|ROI) + (1|SubjectNumber), data = LHLangtoLang)
anova(m1,m0)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", Contrast == 'sent' | Contrast == 'non')
View(LHLangtoLang)
LHLangtoLang <- filter(allSigChange, Group == "LHLang-toLang", contrastName == 'sent' | contrastName == 'non')
View(LHLangtoLang)
RHLangtoLang <- filter(allSigChange, Group == "RHLang-toLang", contrastName == 'sent' | contrastName == 'non')
m1 <- lmer(sigChange ~ contrastName + (1|ROI) + (1|SubjectNumber), data = RHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (1|ROI) + (1|SubjectNumber), data = RHLangtoLang)
anova(m1,m0)
ToMtoToM <- filter(allSigChange, Group == "ToM-toToM", contrastName == 'bel' | contrastName == 'pho')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = LHLangtoLang)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = LHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = LHLangtoLang)
anova(m1,m0)
ToMtoToM <- filter(allSigChange, Group == "ToM-toToM", contrastName == 'bel' | contrastName == 'pho')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = ToMtoToM)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = ToMtoToM)
anova(m1,m0)
RHLang <- filter(allSigChange, Group == "RHLang", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = RHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = RHLangtoLang)
anova(m1,m0)
RHLang <- filter(allSigChange, Group == "RHLang", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = RHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = RHLang)
anova(m1,m0)
LHLang <- filter(allSigChange, Group == "LHLang", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = LHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = LHLang)
anova(m1,m0)
MDRight <- filter(allSigChange, Group == "MDRight", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = MDRight)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = MDRight)
anova(m1,m0)
MDLeft <- filter(allSigChange, Group == "MDLeft", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = MDLeft)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = MDLeft)
anova(m1,m0)
ToM <- filter(allSigChange, Group == "ToM", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROI) + (contrastName|SubjectNumber), data = ToM)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROI) + (contrastName|SubjectNumber), data = ToM)
anova(m1,m0)
ToM_MDRight <- filter(allSigChange, Group == "ToM" | Group = "MDRight", contrastName == 'joke' | contrastName == 'lit')
ToM_MDRight <- filter(allSigChange, Group == "ToM" | Group == "MDRight", contrastName == 'joke' | contrastName == 'lit')
View(ToM_MDRight)
m1 <- lmer(sigChange ~ contrastName*Group + (contrastName*Group|ROI) + (contrastName*Group|SubjectNumber), data = MDLeft)
#Plan: Within each system (localizers, and jokes), test for condition differences
RHLangtoLang <- filter(allSigChange, Group == "RHLang-toLang", contrastName == 'sent' | contrastName == 'non')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLangtoLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = RHLangtoLang)
anova(m1,m0)
ToM_MDRight <- filter(allSigChange, Group == "ToM" | Group == "MDRight", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName*Group + (contrastName*Group|ROIName) + (contrastName*Group|SubjectNumber), data = MDLeft)
m1 <- lmer(sigChange ~ contrastName*Group + (contrastName|ROIName) + (contrastName*Group|SubjectNumber), data = MDLeft)
m1 <- lmer(sigChange ~ contrastName*Group + (contrastName|ROIName) + (contrastName*Group|SubjectNumber), data = ToM_MDRight)
m0 <- lmer(sigChange ~ contrastName+Group + (contrastName|ROIName) + (contrastName*Group|SubjectNumber), data = ToM_MDRight)
anova(m1,m0)
ToM_MDRight_cont <- filter(allSigChange, Group == "ToM" | Group == "MDRight", contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
m1 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDRight_cont)
anova(m1,m0)
unique(allSigChange(contrastName))
unique(allSigChanges(contrastName))
unique(allSigChange$contrastName)
ToMCustom <- <- filter(allSigChange, Group == "ToMCustom", contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
#Make sure those factors are ordered....
type(ToMCustom$contrastName)
ToMCustom$contrastName
ToMCustom <- filter(allSigChange, Group == "ToMCustom", contrastName == 'low' | contrastName == 'med' | contrastName == 'high')
ToMCustom$contrastName
is.ordered(ToMCustom$contrastName)
head(ToMCustom)
is.ordered(ToMCustom$Contrast)
help(as.factor)
ToMCustom$contrastName <- as.factor(ToMCustom$contrastName, as.ordered = TRUE)
is.ordered(ToMCustom$contrastName)
ToMCustom$contrastName <- as.factor(ToMCustom$contrastName)
head(ToMCustom)
is.factor(ToMCustom$contrastName)
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToMCustom)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = ToMCustom)
anova(m1,m0)
ToM_RHLang_cont <- filter(allSigChange, Group == "ToM" | Group == "RHLang", contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_RHLang_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_RHLang_cont)
anova(m1,m0)
ToM_MDLeft_cont <- filter(allSigChange, Group == "ToM" | Group == "MDLeft", contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDLeft_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_MDLeft_cont)
anova(m1,m0)
ToM_LHLang_cont <- filter(allSigChange, Group == "ToM" | Group == "LHLang", contrastName == 'joke-lit')
m1 <- lmer(sigChange ~ Group + (1|ROIName) + (Group|SubjectNumber), data = ToM_LHLang_cont)
m0 <- lmer(sigChange ~ 1 + (1|ROIName) + (Group|SubjectNumber), data = ToM_LHLang_cont)
anova(m1,m0)
LHLang <- filter(allSigChange, Group == "LHLang", contrastName == 'joke' | contrastName == 'lit')
m1 <- lmer(sigChange ~ contrastName + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLang)
m0 <- lmer(sigChange ~ 1 + (contrastName|ROIName) + (contrastName|SubjectNumber), data = LHLang)
anova(m1,m0)
rm(list=ls(all=TRUE))
library(tidyr)
library(dplyr)
#Set wd!
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/reproducible analyses")
rois <- read.csv("roi sizes.csv")
#Let's do a series of Wilcoxon rank sum (unpaired!) tests to see if systems have different sized ROIs
MD <- filter(rois, System == "MD")
TM <- filter(rois, System == "ToM")
LA <- filter(rois, System == "Language") #RH and LH are same bc RH is just the reflection
MDL <- filter(MD, ROI.number %% 2 == 1)
MDR <- filter(MD, ROI.number %% 2 == 0)
help(wilcox.test)
wilcox.test(TM$Size.in.voxels, LA$Size.in.voxels, paired=FALSE)
wilcox.test(MDR$Size.in.voxels, TM$Size.in.voxels, paired=FALSE)
wilcox.test(MDR$Size.in.voxels, LA$Size.in.voxels, paired=FALSE)
summarise(MDR, mean(Size.in.voxels))
summarise(TM, mean(Size.in.voxels))
summarise(LA, mean(Size.in.voxels))
# This file is going to have the full analysis pipeline for the MannerPath studies!
#It will pull data from the main MannerPath_Data.csv and from the trial data
#(Repo/MPP_Stim_and_Data/Data) from each child. There are (currently) two different
#experiments/conditions in the dataset:
#
# MannerPath - the original version (MP learning/bias), with no extension version
# ActionEffect+Extend - AE learning/bias, followed by MP trials which have only bias phase
# Just for super awesome fun times, subjects before #77 in AE-Extend have a variety of
# slightly different matlab outputs, and some of them only have AE data but no extension.
# Hence data cleaning/reformatting is...a bit messy.
#
# See #TODO for unfinished places
# See line 140ish for analysis
######
# LIBRARIES, FILES, DIRECTORIES
######
library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(pwr)
rm(list=ls()) #Clear any lingering variables
#Set directories; might need to change this on your computer!
#repodir = "C:/Users/Anna/Documents/GitHub/MannerPathPriming/"
repodir = "/Users/mekline/Dropbox/_Projects/PrimingMannerPath/MannerPathPriming/"
adir = paste(repodir, "Analysis/", sep="")
ddir = paste(repodir, "MPP_Stim_and_Data/Data/" , sep="")
setwd(repodir)
pFile = paste(repodir,"MannerPath_Data.csv",sep="") #get files ready...
files = list.files(ddir, pattern = ".dat$") #all .dat files in data directory
participantData = read.csv(pFile, sep = ",", header = T) #load the info data file
######
# INCLUSION INFO
######
#TODO: Do inclusion/exclusion of participants up here, with calculations for type of exclusion
#Print nice summary of subject numbers, ages, gender splits up here
######
# DATA CLEANING
######
#loop over files (participants) and the rows in the file
#For now, just read in all lines of every data file. Assert that all have the same columns
#names at the start, but some may have extra columns if they have extension data. Later on we'll
#clean up and reshape to get nicer formatted data.
#Notes:
# - No .dat files for 1,2, 35, 42, 69 (1-2 pilot, 35-69 kids who consented/are on camera
# but didn't get to the exp)
#
# - Lots of errors are printed anytime we hit a badly formatted .dat file
setwd(ddir)
allData <- data.frame(NULL)
error_files = list() #create an empty error list
for (file in files) {
trialData <- try(read.table(file, sep = ",", header = T, fill=T))
if (class(trialData) == 'try-error') {
cat(file)
cat('Caught an error during read.table.\n')
} else {
pData = try(participantData[participantData$Participant.. == trialData$SubjectNo[1],]) #get info for current participant
pData$SubjectNo = pData$Participant..
myData = left_join(trialData, pData, by="SubjectNo") #Build rows
allData <- bind_rows(myData, allData) #Add these rows to the giant data frame
}
}
length(unique(allData$SubjectNo))
#It's a great big data frame! Begin by dropping columns that we don't need for analysis (mostly names of individual vid files)
colToSave = c("SubjectNo","VerbDomain","trialNo","itemID",
"verbName","mannerSideBias","pathSideBias",
"kidResponseBias","mannerSideTest","pathSideTest",
"kidResponseTest","Experiment","Verb.Condition",
"Gender","Days.Old",
"Age.Years","Age.Months","Inclusion.Decision",
"Exclude.Reason","Experiment.Group",
"Experiment.x","Experiment.y","Condition",
"extAnswer","extVerbName",
"extMannerSide","extPathSide")
#Recode variable names
allData$RealExp <- ''
allData$Experiment <- as.character(allData$Experiment)
allData$Experiment.y <- as.character(allData$Experiment.y)
allData <- allData  %>%
select(one_of(colToSave)) %>%
mutate(RealExp = ifelse(is.na(Experiment),Experiment.y,Experiment)) %>% #'Experiment' and 'Condition' were used inconsistently early on but can be derived from levels used
select(-c(VerbDomain, Experiment, Experiment.Group, Experiment.y, Experiment.x, Condition)) %>%
rename(Experiment = RealExp) %>%
rename(Condition = Verb.Condition)
allData1 <- allData %>% #A few participants had the extension trials coded on the same lines as trials 1-8, just have to rearrange them
filter(is.na(extAnswer))
allData2 <- allData %>%
filter(!is.na(extAnswer))
#this could all be a gather probably, but it aint working
allDataBase <- select(allData2, -c(extAnswer, extVerbName, extMannerSide, extPathSide))
allDataExtend <- select(allData2, -c(itemID,verbName,mannerSideBias,pathSideBias,kidResponseBias,mannerSideTest,pathSideTest,kidResponseTest))
allDataExtend <- allDataExtend %>%
mutate(trialNo = trialNo + 8) %>%
rename(verbName = extVerbName)  %>%
rename(mannerSideBias = extMannerSide) %>%
rename(pathSideBias = extPathSide) %>%
rename(kidResponseBias = extAnswer)
allDataExtend$itemID = 'get it from verbname'
allDataExtend$mannerSideTest = 'undefined'
allDataExtend$pathSideTest = 'undefined'
allDataExtend$kidResponseTest = 'undefined'
allData <- select(allData1, -c(extAnswer, extVerbName, extMannerSide, extPathSide)) %>% #re-adding the normal ones
rbind(allDataBase) %>% #add base, then ext. trials of the weirdos
rbind(allDataExtend) %>%
arrange(SubjectNo) %>%
select(Experiment,Condition,SubjectNo,trialNo,itemID,verbName, mannerSideBias:Exclude.Reason) #just reordering
#rm(list=setdiff(ls(), c("allData","adir","ddir","repodir")))#avoid accidentally referencing placeholder vars from above
allData <- allData %>%
filter(!is.na(Inclusion.Decision)) %>%
filter(Inclusion.Decision == 1) %>% #TODO: Eventually do this above and report stats!
select(-c(Inclusion.Decision, Exclude.Reason))
######
# DATA RESHAPE FOR ANALYSIS & GRAPHS
######
#TODO: Probably a good idea to print out a sanitized csv here for people who don't want to run the data cleaning....
#TODO: Checks for effects of side bias go here
allData <- allData %>% #Translate kid choice variables to objective 'choseM' for Bias (main) & Test (sanity check - did they learn the verb)
filter(kidResponseBias == 'z' | kidResponseBias == 'c') %>% #remove trials w/ no answer on critical Bias q
mutate(choseM.Bias = ifelse((mannerSideBias == "L" & kidResponseBias == "z")|
(mannerSideBias == "R" & kidResponseBias == "c"), 1, 0)) %>%
mutate(choseM.Test = ifelse((mannerSideTest == "L" & kidResponseTest == "z")|
(mannerSideTest == "R" & kidResponseTest == "c"), 1, 0)) %>%
mutate(expPhase = ifelse(trialNo>8,"Extension","Base")) #Mark trials 1-8 and 9-16
######
#IMPORTANT!
######
allData <- filter(allData, trialNo>1) #Trial #1 Bias test is pre-training!!
#Anna run to here
######
# GRAPHS
######
makePlot = function(ydata, ylab="proportion chosing Manner/Action", title=""){
plotData <- aggregate(ydata$choseM.Bias, by=list(ydata$Condition,  ydata$trialNo), sum)
numObs <- aggregate(ydata$choseM.Bias, by=list(ydata$Condition, ydata$trialNo), length)
names(plotData) <- c("Condition", "trialNo", "choseManner")
plotData$numObs <- numObs$x
#get the binomial conf.intervals per condition per trial
for (cond in unique(plotData$Condition))
{
for (trial in unique(plotData[plotData$Condition == cond,]$trialNo))
{
x = plotData[plotData$Condition == cond & plotData$trialNo == trial,]$choseManner
n = plotData[plotData$Condition == cond & plotData$trialNo == trial,]$numObs
test = prop.test(x, n, conf.level=0.95)
plotData$intLower[plotData$Condition == cond & plotData$trialNo == trial] = test$conf.int[1]
plotData$intUpper[plotData$Condition == cond & plotData$trialNo == trial]  = test$conf.int[2]
plotData$theAvg[plotData$Condition == cond & plotData$trialNo == trial] = x/n
}
}
#print(plotData)
#make a plot with ggplot
pd <- position_dodge(0.1)
ggplot(plotData, aes(x=trialNo, y=theAvg, colour=Condition, group=Condition, ymax = 1)) +
geom_errorbar(aes(ymin=intLower, ymax=intUpper), colour="black", width=.1, position=pd) +
geom_line(position=pd) +
ylab(ylab) +
geom_point(position=pd, size=3) +
coord_cartesian(ylim=c(0,1)) +
ggtitle(title)
#scale_colour_manual(values = c("green","red"),
#name="",
#labels=c("Manner", "Path")) +
}
makePlot(filter(allData, Condition == "Action" | Condition == "Effect"))
makeBar = function(ydata, ylab="proportion chosing Manner/Action", title="") {
plotData <- aggregate(ydata$choseM.Bias, by=list(ydata$Condition, ydata$expPhase), sum)
numObs <- aggregate(ydata$choseM.Bias, by=list(ydata$Condition, ydata$expPhase), length)
names(plotData) <- c("Condition", "Phase", "choseManner")
plotData$numObs <- numObs$x
print(plotData)
for (cond in unique(plotData$Condition)){
for (ph in unique(plotData$Phase)){
x = plotData[plotData$Condition == cond & plotData$Phase == ph,]$choseManner
n = plotData[plotData$Condition == cond & plotData$Phase == ph,]$numObs
test = prop.test(x, n, conf.level=0.95)
plotData$intLower[plotData$Condition == cond & plotData$Phase == ph] = test$conf.int[1]
plotData$intUpper[plotData$Condition == cond & plotData$Phase == ph]  = test$conf.int[2]
plotData$theAvg[plotData$Condition == cond & plotData$Phase == ph] = x/n
}
}
ggplot(plotData, aes(x=Phase, y=theAvg, fill=Condition)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=intLower, ymax=intUpper), colour="black", width=.1, position=position_dodge(.9)) + #Why point 9? Hell if I know!
coord_cartesian(ylim=c(0,1))+
ylab(ylab)+
xlab('')+
theme_bw()+
#scale_colour_manual(values = c("green","red")) +
#scale_fill_brewer(palette=colors) +
ggtitle(title)
}
makeBar(filter(allData, Condition == "Action" | Condition == "Effect"))
